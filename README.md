# devsoc
#The program demonstrates the creation of a basic neural network in Python for classifying digits from the MNIST dataset. The process begins with loading and preprocessing the data, which is then divided into training and development sets. The pixel values are normalized by dividing by 255.0 to scale them between 0 and 1. Core components of the neural network include the 'Linear' layer for linear transformations, the 'ReLU' activation function for non-linearity, the 'Softmax' function for probabilities, and the 'CrossEntropyLoss' class for loss computation. The 'SGD' optimizer updates the model's weights and biases using the calculated gradients. The 'NeuralNetwork' class is used as the main framework for building and training the model. The model is trained for 150 epochs, performing forward propagation for predictions, computing the loss, and using backpropagation to adjust weights. The model is evaluated on a separate development set to evaluate its generalization to unseen data.
