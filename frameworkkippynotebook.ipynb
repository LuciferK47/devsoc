{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30035,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\ndata = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-12T13:56:11.425442Z","iopub.execute_input":"2024-08-12T13:56:11.425871Z","iopub.status.idle":"2024-08-12T13:56:14.671560Z","shell.execute_reply.started":"2024-08-12T13:56:11.425818Z","shell.execute_reply":"2024-08-12T13:56:14.670289Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nclass NeuralNetwork:\n    def __init__(self):\n        self.layers = []\n        self.loss = None\n        self.optimizer = None\n\n    def load_data(self, file_path):\n        # Implement data loading from CSV\n        return np.genfromtxt(file_path, delimiter=',', skip_header=1)\n\n    def shuffle_data(self, data):\n        np.random.shuffle(data)\n\n    def sub_array(self, array, start, end):\n        return array[start:end]\n\n    def transpose(self, matrix):\n        return np.transpose(matrix)\n\n    def add_layer(self, layer):\n        self.layers.append(layer)\n\n    def compile(self, loss, optimizer):\n        self.loss = loss\n        self.optimizer = optimizer\n\n    def forward(self, X):\n        for layer in self.layers:\n            X = layer.forward(X)\n        return X\n\n    def backward(self, grad_output):\n        for layer in reversed(self.layers):\n            grad_output = layer.backward(grad_output)\n\n    def train(self, X, y, epochs):\n        for epoch in range(epochs):\n            y_pred = self.forward(X)\n            loss_value = self.loss.forward(y_pred, y)\n            grad_output = self.loss.backward(y_pred, y)\n            self.backward(grad_output)\n            self.optimizer.step(self.layers)\n            print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss_value:.4f}')\n\n    def predict(self, X):\n        return self.forward(X)\n\n    def evaluate(self, X, y):\n        y_pred = self.predict(X)\n        loss_value = self.loss.forward(y_pred, y)\n        accuracy = np.mean(np.argmax(y_pred, axis=1) == y)\n        print(f'Loss: {loss_value:.4f}, Accuracy: {accuracy:.4f}')\n\nclass Linear:\n    def __init__(self, input_dim, output_dim):\n        self.weights = np.random.randn(input_dim, output_dim) * 0.01\n        self.bias = np.zeros((1, output_dim))\n        self.input = None\n        self.grad_weights = None\n        self.grad_bias = None\n\n    def forward(self, X):\n        self.input = X\n        return np.dot(X, self.weights) + self.bias\n\n    def backward(self, grad_output):\n        self.grad_weights = np.dot(self.input.T, grad_output)\n        self.grad_bias = np.sum(grad_output, axis=0, keepdims=True)\n        return np.dot(grad_output, self.weights.T)\n\nclass ReLU:\n    def __init__(self):\n        self.input = None\n\n    def forward(self, X):\n        self.input = X\n        return np.maximum(0, X)\n\n    def backward(self, grad_output):\n        return grad_output * (self.input > 0)\n\nclass Softmax:\n    def __init__(self):\n        self.output = None\n\n    def forward(self, X):\n        exp_values = np.exp(X - np.max(X, axis=1, keepdims=True))\n        self.output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n        return self.output\n\n    def backward(self, grad_output):\n        return grad_output  # Simplified for this implementation\n\nclass CrossEntropyLoss:\n    def forward(self, y_pred, y_true):\n        samples = len(y_pred)\n        y_pred_clipped = np.clip(y_pred, 1e-12, 1. - 1e-12)\n        correct_confidences = y_pred_clipped[range(samples), y_true]\n        return -np.mean(np.log(correct_confidences))\n\n    def backward(self, y_pred, y_true):\n        samples = len(y_pred)\n        grad = y_pred\n        grad[range(samples), y_true] -= 1\n        return grad / samples\n\nclass SGD:\n    def __init__(self, learning_rate=0.01):\n        self.learning_rate = learning_rate\n\n    def step(self, layers):\n        for layer in layers:\n            if hasattr(layer, 'weights'):\n                layer.weights -= self.learning_rate * layer.grad_weights\n                layer.bias -= self.learning_rate * layer.grad_bias\n\n\nif __name__ == '__main__':\n    \n    nn = NeuralNetwork()\n    data = nn.load_data('/path/to/train.csv')\n    m, n = data.shape\n\n    \n    nn.shuffle_data(data)\n\n    \n    data_dev = nn.transpose(nn.sub_array(data, 0, 1000))\n    Y_dev = data_dev[0]\n    X_dev = nn.transpose(nn.sub_array(data_dev, 1, len(data_dev))) / 255.0\n\n    data_train = nn.transpose(nn.sub_array(data, 1000, m))\n    y_train = data_train[0]\n    x_train = nn.transpose(nn.sub_array(data_train, 1, len(data_train))) / 255.0\n\n    \n    model = NeuralNetwork()\n    model.add_layer(Linear(784, 128))\n    model.add_layer(ReLU())\n    model.add_layer(Linear(128, 10))\n    model.add_layer(Softmax())\n\n    \n    loss = CrossEntropyLoss()\n    optimizer = SGD(learning_rate=0.2)\n    model.compile(loss, optimizer)\n\n    \n    model.train(x_train, y_train, epochs=150)\n\n    \n    model.evaluate(X_dev, Y_dev)\n\n\n\n\n    \n\n   \n      \n\n\n       ","metadata":{"execution":{"iopub.status.busy":"2024-08-12T13:56:15.467262Z","iopub.execute_input":"2024-08-12T13:56:15.467607Z","iopub.status.idle":"2024-08-12T13:56:15.515949Z","shell.execute_reply.started":"2024-08-12T13:56:15.467575Z","shell.execute_reply":"2024-08-12T13:56:15.514712Z"},"trusted":true},"execution_count":20,"outputs":[]}]}